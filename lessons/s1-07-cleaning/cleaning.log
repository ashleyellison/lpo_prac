------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/cleaning.log
  log type:  text
 opened on:  14 Oct 2020, 11:14:59

. 
. // NAME: Data cleaning
. // FILE: cleaning.do
. // AUTH: Will Doyle
. // REVS: Benjamin Skinner
. // INIT: 15 October 2014
. // LAST: 14 October 2020
.   
. clear all                               // clear memory

. set more off                            // turn off annoying "__more__" feature

. 
. 
. /***
> 
> Variable labels
> ---------------
> 
> Not everyone you work with will be as well-trained as you. Large datasets that are appen
> ded over time (think institutional data) also have a tendency to suffer from drift or en
> tropy. Many times you will receive a dataset with incomplete or incomprehensible variabl
> e labels. You will need to figure out what to do with these. The labels in this example 
> dataset are obviously a mess.
> 
> ***/
. 
. 
. // load CA school data with problems
. use caschool_problem, replace

. 
. 
. 
. /***
> Techniques for working with single variables
> --------------------------------------------
> 
> Each of the following describes techniques that can help you to find data points that ma
> y be unreliable or wrong. When you find such a data point, you need to rely on your judg
> ment and the context of the problem to decide what to do next.
> 
> ### Outliers
> 
> Look for outliers: values that are extraordinarily far from the mean or median (e.g., mo
> re than 3 s.d. away for approximately normal data).
> 
> Let's take a look at student teacher ratio using the {c 96}boxplot{c 96} and {c 96}histo
> gram{c 96} commands.
> ***/
. 
. 
. // LOOKING FOR OUTLIERS WITH VARIOUS PLOTS
. 
. // box plot str
. graph box str, name(box_str)

. graph export  box_str.png, name(box_str) replace
(file /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/box_str.png written in PNG format)

. 
. // histogram str
. histogram str, name(hist_str)
(bin=20, start=14, width=1.6700001)

. graph export  hist_str.png, name(hist_str) replace
(file /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/hist_str.png written in PNG format)

. 
. /***
> 
> /***
> 
> <img src = "box_str.png" />
> 
> 
> <img src = "hist_str.png" />
> 
> 
> ***/
> 
> 
> <br>
> 
> As you can see, there are two values of student teacher ratio that are big outliers. Wha
> t should we do about these?
> 
> <br>
> 
> #### Quick Exercise
> 
> There's another variable that has an extreme outlier. Find this variable and decide what
>  to do about it.
> 
> <br>
> 
> 
> 
> ***/
. 
. /***
> 
> ### Impossible values
> 
> You should also look for impossible values. These include: negative values for things th
> at must be positive like income or height; test scores that are above the maximum; propo
> rtions that are negative or above one; or percentages that are negative or above 100.
> 
> Here's a summary of the {c 96}calw_pct{c 96} variable, which is expressed in percentage 
> terms. It clearly has at least one impossible value.
> 
> 
> ***/
. 
. // IMPOSSIBLE VALUES 
. 
. // summarize calw percent
. sum calw_pct

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
    calw_pct |        420    13.46038    12.25822          0      102.7

. 
. // Remove impossible values for calworks because some schools recorded more than 100
. replace calw_pct =. if calw_pct>100
(1 real change made, 1 to missing)

. 
. /***
> 
> ### Data that are off trend
> 
> When looking at data that are in panel format, very sharp changes from the previous peri
> od may be suspect. For instance, a student who goes from the 5th percentile to the 95th 
> percentile in test scores.
> 
> 
> ***/
. 
. // LOOKING FOR IMPLAUSIBLE VALUES WITH VARIOUS PLOTS
. 
. /***
> ### Checking relationships
> 
> Check to make sure that the variable is in the order that you would expect in the compar
> ison. Are there high income students that are coded as low SES? Are there students with 
> low GPAs and high test scores? These may be correct, but you need to check for strange p
> atterns.
> 
> To test this, let's plot several of the variables against one another and look for probl
> ematic relationships. Here's a plot of average income, {c 96}avginc{c 96}, against the p
> ercent of students in the district on free or reduced price lunches, {c 96}meal_pct{c 96
> }:
> ***/
. 
. // twoway scatter of avginc and meal_pct
. graph twoway scatter avginc meal_pct, name(sc_inc_meal)

. graph export  sc_inc_meal.png, name(sc_inc_meal) replace
(file /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/sc_inc_meal.png written in PNG format
> )

. 
. 
. 
. /***
> 
> <img src = "sc_inc_meal.png" />
> 
> ***/
. 
. 
. /***
> #### Quick Exercise
> 
> > There's another implausible value based on the relationship between two variables. Fin
> d it. (Hint: what is the biggest budget item in any school district?) <br>
> ***/
. 
. 
. /***
> 
> ### Logically impossible combinations
> 
> Check that there aren't logically impossible combinations of variables. For example, we 
> should be suspicious when a parent's age is less than that of the student. Sometimes you
> r dataset documentation will alert you to potential problems. The codebook of the Nation
> al Longitudinal Survey of Youth, 1997, helpfully explains that "researchers should note 
> that \[work hour\] totals above 168 hours per week are suspect."
> 
> <br>
> 
> 
> ***/
. 
. /***
> 
> Check calculations
> ------------------
> 
> Check to make sure that calculations have been done correctly. For example this dataset 
> has several ratio measures. Let's recalculate these and see if they are correct. In the 
> code below we recalculate the student teacher ratio and then plot it against the origina
> l calculation.
> 
> 
> ***/
. 
. 
. // CHECKING CALCUATIONS
. 
. // create new student teacher ratio variable
. gen str_two = enrl_tot / teachers

. 
. // twoway scatter of both student teacher ratio variables
. graph twoway scatter str_two str, name(sc_str_str_two)

. graph export  sc_str_two.png, name(sc_str_str_two) replace
(file /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/sc_str_two.png written in PNG format)

. 
. 
. /***
> 
> <img src = "sc_str_two.png" />
> 
> ***/
. 
. 
. /***
> 
> <br>
> 
> That's not good. Not good at all. {c 96}teacher{c 96} has a lot of the same -4 values. M
> aybe that means something. Clearly a school can't have -4 teachers. Let's recompute the 
> ratio but only for schools with a positive number of teachers.
> 
> ***/
. 
. // assume negative means missing and drop
. replace teachers = . if teachers == -4
(67 real changes made, 67 to missing)

. 
. // create another new student teacher ratio variable
. gen str_three = enrl_tot / teachers
(67 missing values generated)

. 
. // twoway scatter of new new and old student teacher ratio variables
. graph twoway scatter str_three str, name(sc_str_str_three)

. graph export  sc_str_str_three.eps, name(sc_str_str_three) replace
(file sc_str_str_three.eps written in EPS format)

. 
. /***
> #### Quick Exercise
> 
> > There are other variables with problems in their calculations. Find them.
> 
> <br>
> ***/
. 
. /***
> Duplicates
> ----------
> 
> You'll also need to look for duplicates in variables that shouldn't have any. The most o
> bvious place to look is in *id* numbers or the equivalent. You should also check any oth
> er variable that ought to be unique. Luckily, Stata has a whole suite of duplicate comma
> nds to work with, including, the appropriately named {c 96}duplicates{c 96}.
> 
> Below is an example of a variable with no duplicates, followed by a variable with a coup
> le of duplicates.
> ***/
. 
. 
. // LOOKING FOR DUPLICATES 
. 
. // check for duplicate observations
. duplicates report observation_number

Duplicates in terms of observation_number

--------------------------------------
   copies | observations       surplus
----------+---------------------------
        1 |          420             0
--------------------------------------

. 
. // check for duplicate district cod
. duplicates report dist_cod

Duplicates in terms of dist_cod

--------------------------------------
   copies | observations       surplus
----------+---------------------------
        1 |          418             0
        2 |            2             1
--------------------------------------

. 
. /***
> Missing data
> ------------
> 
> ### Find missing data codes
> 
> First, figure out how missing data is coded from the codebook. Code those values as miss
> ing. That's a dot, {c 96}.{c 96}, in Stata.
> 
> <br>
> ***/
. 
. 
. // CHECK FOR NEGATIVE VALUES, MISSING DATA
. 
. // inspect test scores
. inspect testscr

testscr:  API INDEX                             Number of Observations
-------------------                    ---------------------------------------
                                             Total      Integers   Nonintegers
|          #                 Negative            -             -             -
|          #                 Zero                -             -             -
|      #   #                 Positive          420            17           403
|      #   #   #                       -----------   -----------   -----------
|      #   #   #             Total             420            17           403
|  #   #   #   #   .         Missing             -
+----------------------                -----------
605.55           706.75                        420
(More than 99 unique values)

. 
. // inspect reading scores
. inspect read_scr

read_scr:                                       Number of Observations
-----------                            ---------------------------------------
                                             Total      Integers   Nonintegers
|                  #         Negative           77            77             -
|                  #         Zero               15            15             -
|                  #         Positive          328            33           295
|                  #                   -----------   -----------   -----------
|                  #         Total             420           125           295
|  #   .   .   .   #         Missing             -
+----------------------                -----------
-1                  704                        420
(More than 99 unique values)

. 
. // plot reading scores for further investigation
. histogram read_scr, name(hist_read_scr)
(bin=20, start=-1, width=35.25)

. graph export hist_read_scr.png, name(hist_read_scr) replace
(file /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/hist_read_scr.png written in PNG form
> at)

. 
. 
. /***
> <img src = "hist_read_scr.png" />
> ***/
. 
. /***                                              
> ### Recode problematic data points as missing
> 
> Next, look for impossible values as above. These should also be recoded to missing.
> 
> <br>
> ***/
. 
. /***
> ### Dealing with zeros
> 
> Now, look for zeros. Are these really zeros? What was the criteria for having a zero? Ch
> eck if these should really be missing.
> 
> Your best friend here is the Stata command {c 96}inspect{c 96}. Here's the result of the
>  {c 96}inspect{c 96} command for two of the variables:
> ***/
. 
. /***
> #### Quick Exercise
> 
> > Look for other variables with either negative or missing values and figure out what do
>  with them. Once you've got the data properly coded and missing entered as missing, use 
> the {c 96}mvpatterns{c 96} command to figure out if there are systematic problems with y
> our data.
> 
> <br>
> ***/
. 
. /***
> 
> Conclusion
> ----------
> 
> All of the above is only to get you started. There is no cookbook way to approach data c
> leaning. The idea is to get to know the data well enough that you know whether anomalies
>  are just strange, but true, or problems in the data itself. 
> 
> <br><br>
> 
> 
> ***/
. 
. // end file     
. log close
      name:  <unnamed>
       log:  /Users/doylewr/lpo_prac/lessons/s1-07-cleaning/cleaning.log
  log type:  text
 closed on:  14 Oct 2020, 11:15:06
------------------------------------------------------------------------------------------
